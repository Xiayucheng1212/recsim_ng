{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                             embedding_cat_headline  \\\n",
      "0       50346  [-0.018390951678156853, 0.00830016192048788, 0...   \n",
      "1       50356  [-0.011984625831246376, -0.007588221691548824,...   \n",
      "2       57628  [-0.020466890186071396, 0.017243118956685066, ...   \n",
      "3       63176  [-0.006752511486411095, -0.008794428780674934,...   \n",
      "4       64463  [-0.023287193849682808, 0.0003693056642077863,...   \n",
      "5       64476  [0.0009472903329879045, -0.008034930564463139,...   \n",
      "6       66138  [-0.016023065894842148, -0.011005213484168053,...   \n",
      "7       66139  [-0.012922842055559158, 0.010963845998048782, ...   \n",
      "8       66144  [-0.007001790683716536, -0.02618696354329586, ...   \n",
      "9       66879  [-0.018545327708125114, -0.014058117754757404,...   \n",
      "\n",
      "                               embedding_description  \n",
      "0  [0.0075088865123689175, 0.0004971068701706827,...  \n",
      "1  [-0.012862027622759342, -0.008416718803346157,...  \n",
      "2  [-0.01038492750376463, -0.011509961448609829, ...  \n",
      "3  [-0.02313167229294777, -0.011342558078467846, ...  \n",
      "4  [0.004991084802895784, -0.00013448660320136696...  \n",
      "5  [0.007531581912189722, -0.029027828946709633, ...  \n",
      "6  [-0.01533524040132761, -0.006003232207149267, ...  \n",
      "7  [-0.013258206658065319, -0.011069835163652897,...  \n",
      "8  [0.0050837136805057526, -0.03594246506690979, ...  \n",
      "9  [-0.009229715913534164, -0.00830544251948595, ...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9750, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "# load data\n",
    "datafile_path_v3 = \"./data/embeddings_10k_v3.csv\"\n",
    "datafile_path = \"./data/embeddings_10k.csv\"\n",
    "datafile_path_v2 = \"./data/embeddings_10k_v2.csv\"\n",
    "\n",
    "df = pd.read_csv(datafile_path_v3)\n",
    "\n",
    "df_v1 = pd.read_csv(datafile_path)\n",
    "df_v2 = pd.read_csv(datafile_path_v2)\n",
    "print(df_v2.head(10))\n",
    "df_v2['category_encoded'] = df_v1['category_encoded']\n",
    "df_v2.to_csv(datafile_path_v2)\n",
    "\n",
    "\n",
    "df[\"embedding_cat_headline\"] = df.embedding_cat_headline.apply(literal_eval).apply(np.array)  # convert string to numpy array\n",
    "cat_matrix = np.vstack(df.category_encoded.values)\n",
    "matrix = np.vstack(df.embedding_cat_headline.values)\n",
    "cat_matrix.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "idx = 3\n",
    "tf.one_hot(5, depth=5).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                             embedding_cat_headline  \\\n",
      "0       50346  [-0.018390951678156853, 0.00830016192048788, 0...   \n",
      "1       50356  [-0.011984625831246376, -0.007588221691548824,...   \n",
      "2       57628  [-0.020466890186071396, 0.017243118956685066, ...   \n",
      "3       63176  [-0.006752511486411095, -0.008794428780674934,...   \n",
      "4       64463  [-0.023287193849682808, 0.0003693056642077863,...   \n",
      "5       64476  [0.0009472903329879045, -0.008034930564463139,...   \n",
      "6       66138  [-0.016023065894842148, -0.011005213484168053,...   \n",
      "7       66139  [-0.012922842055559158, 0.010963845998048782, ...   \n",
      "8       66144  [-0.007001790683716536, -0.02618696354329586, ...   \n",
      "9       66879  [-0.018545327708125114, -0.014058117754757404,...   \n",
      "\n",
      "                               embedding_description  category_encoded  \n",
      "0  [0.0075088865123689175, 0.0004971068701706827,...                 0  \n",
      "1  [-0.012862027622759342, -0.008416718803346157,...                 0  \n",
      "2  [-0.01038492750376463, -0.011509961448609829, ...                 0  \n",
      "3  [-0.02313167229294777, -0.011342558078467846, ...                 0  \n",
      "4  [0.004991084802895784, -0.00013448660320136696...                 0  \n",
      "5  [0.007531581912189722, -0.029027828946709633, ...                 0  \n",
      "6  [-0.01533524040132761, -0.006003232207149267, ...                 0  \n",
      "7  [-0.013258206658065319, -0.011069835163652897,...                 0  \n",
      "8  [0.0050837136805057526, -0.03594246506690979, ...                 0  \n",
      "9  [-0.009229715913534164, -0.00830544251948595, ...                 0  \n"
     ]
    }
   ],
   "source": [
    "print(df_v2.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category_encoded\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 1536)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters = 42\n",
    "init_centroids = []\n",
    "for i in range(n_clusters):\n",
    "    init_centroids.append(df[df['category_encoded'] == i].sample(150).embedding_cat_headline.mean())\n",
    "init_centroids = np.array(init_centroids)\n",
    "init_centroids.shape\n",
    "\n",
    "# for i in range(n_clusters):\n",
    "#     print(df[df['category_encoded'] == i].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EmilyXia\\anaconda3\\envs\\tensor_py3.8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\EmilyXia\\anaconda3\\envs\\tensor_py3.8\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: RuntimeWarning: Explicit initial center position passed: performing only one init in KMeans instead of n_init=10.\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19, 20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38, 39: 39, 40: 40, 41: 41}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, init=init_centroids, random_state=7)\n",
    "kmeans.fit(matrix)\n",
    "labels = kmeans.labels_\n",
    "df[\"Cluster\"] = labels\n",
    "\n",
    "# print(df.groupby(\"Cluster\").apply(lambda x: x)['category_encoded'])\n",
    "df.groupby(\"Cluster\").apply(lambda x: x)['category_encoded'].to_csv('./data/cluster_category.csv')\n",
    "\n",
    "# cluster_cat_df = pd.read_csv('./data/cluster_category.csv')\n",
    "# cluster_cat_count = []\n",
    "# for i in range(n_clusters):\n",
    "#     cluster_cat_count.append(cluster_cat_df.loc[cluster_cat_df['Cluster'] == i].category_encoded.value_counts())\n",
    "    # print(\"cluster num:\", i)\n",
    "    # print(\"total count: \", cluster_cat_df.loc[cluster_cat_df['Cluster'] == i].count())\n",
    "    # print(cluster_cat_df.loc[cluster_cat_df['Cluster'] == i].category_encoded.value_counts())\n",
    "# print(cluster_cat_count)\n",
    "# for cluster, cat in df.groupby(\"Cluster\").apply(lambda x: x)['category_encoded']:\n",
    "    \n",
    "\n",
    "# print(df.groupby(\"Cluster\").apply(lambda x: x.category_encoded.value_counts().idxmax()))\n",
    "cluster_category_mapping = df.groupby(\"Cluster\").apply(lambda x: x.category_encoded.value_counts().idxmax()).to_dict()\n",
    "print(cluster_category_mapping)\n",
    "cluster_centers = df.groupby(\"Cluster\").embedding_cat_headline.mean()\n",
    "# cluster_centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41}\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "valuess = []\n",
    "for key, value in cluster_category_mapping.items():\n",
    "    valuess.append(value)\n",
    "\n",
    "print(set( valuess))\n",
    "print(len(set( valuess)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edward2  as ed\n",
    "import tensorflow as tf\n",
    "# choose several near classes if the distances are smaller than the threshold\n",
    "def choose_near_classes(embed, num_near_classes, threshold, class_centers, category_encoded):\n",
    "    chosen_classes = []\n",
    "    for i, center in enumerate(class_centers):\n",
    "        dis = np.linalg.norm(embed - center)\n",
    "        if dis < threshold and i != category_encoded:\n",
    "            chosen_classes.append([i, dis])\n",
    "    chosen_classes = sorted(chosen_classes, key=lambda x: x[1])\n",
    "    home_dis = np.linalg.norm(embed - class_centers[category_encoded][0])\n",
    "    return (chosen_classes[:num_near_classes], home_dis)\n",
    "\n",
    "# output the class feature value: 1.0 -> dis btw doc and home class center, value -> dis btw doc and other class center/ dis btw doc and home class center\n",
    "def get_class_feature_value(near_classes, home_dis, num_classes, category_encoded):\n",
    "    doc_topic_feature = np.zeros(num_classes)\n",
    "    doc_topic_feature[category_encoded] = 1.0\n",
    "    for i in near_classes:\n",
    "        doc_topic_feature[i[0]] = (home_dis / (i[1]))**2\n",
    "        if doc_topic_feature[i[0]] >= 1.0:\n",
    "            doc_topic_feature[i[0]] = 1.0\n",
    "    add_category_proportion = ed.Normal(loc=tf.one_hot(category_encoded, depth=n_clusters), scale=0.1)[0].numpy()\n",
    "    \n",
    "    return doc_topic_feature + add_category_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 0.4228657514237364], [1, 0.43136076953012936], [36, 0.46456037163918334], [8, 0.5043451942637044], [29, 0.5087263184723162], [26, 0.5150867067190147], [39, 0.5171821479971169], [17, 0.5258631482908701], [10, 0.5273955358335789], [23, 0.5281686219624304]]\n",
      "0.38652283764341117\n",
      "[ 2.04163504  0.81147355  0.05362349  0.16398956 -0.05585576  0.16629182\n",
      " -0.08400556  0.99733247  0.58653944  0.0053992   0.64485358 -0.075789\n",
      "  0.01266128 -0.03722953  0.1428196  -0.05419638  0.08138285  0.49093105\n",
      "  0.06904712  0.01656412  0.15746444 -0.03220402  0.02197926  0.64910131\n",
      "  0.0758355  -0.0686548   0.58307464  0.06535009 -0.1509354   0.49867999\n",
      "  0.0087642  -0.00633169  0.20451856 -0.1128444   0.0549478   0.06469816\n",
      "  0.8196901   0.07163695 -0.1507657   0.69814045 -0.05620434 -0.10904837]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "near_classes = choose_near_classes(matrix[10], 10, 0.6, cluster_centers.values, cat_matrix[10])\n",
    "print(near_classes[0])\n",
    "print(near_classes[1])\n",
    "doc_topic_feature = get_class_feature_value(near_classes[0], near_classes[1], 42, cat_matrix[10])\n",
    "print(doc_topic_feature)\n",
    "all_doc_topic_feature = []\n",
    "# print(len(all_doc_topic_feature[0]))\n",
    "for i, x in enumerate(matrix):\n",
    "    near_classes = choose_near_classes(x, 4, 0.6, cluster_centers.values, cat_matrix[i])\n",
    "    doc_topic_feature = get_class_feature_value(near_classes[0], near_classes[1], n_clusters, cat_matrix[i])\n",
    "    all_doc_topic_feature.append(doc_topic_feature)\n",
    "# save to csv file && add header\n",
    "df_topic = pd.DataFrame(all_doc_topic_feature)\n",
    "df_topic.to_csv('./data/doc_vector_feature.csv', index=False)\n",
    "\n",
    "# test outcome\n",
    "# df_topic = pd.read_csv('./data/doc_vector_feature.csv', index_col=False)\n",
    "# features = np.array(df_topic.values)\n",
    "# print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
